{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pt파일로부터 fine-tune 된 ResNet-50 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models.resnet import resnet50\n",
    "\n",
    "\n",
    "finetuned_resnet = resnet50()\n",
    "finetuned_resnet.load_state_dict(torch.load(\"../finetuned_resnet50/Res_Sim_RoI.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ckpt파일로부터 fine-tune 된 DeTR 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.88s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of training examples: 19393\n",
      "Number of validation examples: 2466\n",
      "Number of test examples: 2443\n"
     ]
    }
   ],
   "source": [
    "# DeTR 모델 정의\n",
    "from transformers import DetrForObjectDetection, DetrImageProcessor\n",
    "import os\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DetrForObjectDetection\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "# Huggingface에서 pretrained model 로드\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "CHECKPOINT = 'facebook/detr-resnet-50'\n",
    "\n",
    "\n",
    "image_processor = DetrImageProcessor.from_pretrained(CHECKPOINT)\n",
    "model = DetrForObjectDetection.from_pretrained(CHECKPOINT)\n",
    "\n",
    "# Dataset 정의\n",
    "dataset_location = f\"/mnt/d/Data/811_dataset\"\n",
    "ANNOTATION_FILE_NAME = \"labels.json\"\n",
    "TRAIN_DIRECTORY = os.path.join(dataset_location, \"train\")\n",
    "VAL_DIRECTORY = os.path.join(dataset_location, \"val\")\n",
    "TEST_DIRECTORY = os.path.join(dataset_location, \"test\")\n",
    "\n",
    "\n",
    "class CocoDetection(torchvision.datasets.CocoDetection):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_directory_path: str,\n",
    "        image_directory_path: str, \n",
    "        image_processor, \n",
    "        train: bool = True\n",
    "    ):\n",
    "        annotation_file_path = os.path.join(image_directory_path, ANNOTATION_FILE_NAME)\n",
    "        super(CocoDetection, self).__init__(image_directory_path, annotation_file_path)\n",
    "        self.image_processor = image_processor\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        images, annotations = super(CocoDetection, self).__getitem__(idx)        \n",
    "        image_id = self.ids[idx]\n",
    "        annotations = {'image_id': image_id, 'annotations': annotations}\n",
    "        encoding = self.image_processor(images=images, annotations=annotations, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze()\n",
    "        target = encoding[\"labels\"][0]\n",
    "\n",
    "        return pixel_values, target\n",
    "\n",
    "\n",
    "TRAIN_DATASET = CocoDetection(\n",
    "    dataset_directory_path=f\"{TRAIN_DIRECTORY}\",\n",
    "    image_directory_path=f\"{TRAIN_DIRECTORY}//data\", \n",
    "    image_processor=image_processor,\n",
    "    train=True)\n",
    "VAL_DATASET = CocoDetection(\n",
    "    dataset_directory_path=f\"{VAL_DIRECTORY}\",\n",
    "    image_directory_path=f\"{VAL_DIRECTORY}//data\", \n",
    "    image_processor=image_processor, \n",
    "    train=False)\n",
    "TEST_DATASET = CocoDetection(\n",
    "    dataset_directory_path=f\"{TEST_DIRECTORY}\",\n",
    "    image_directory_path=f\"{TEST_DIRECTORY}//data\", \n",
    "    image_processor=image_processor, \n",
    "    train=False)\n",
    "\n",
    "print(\"Number of training examples:\", len(TRAIN_DATASET))\n",
    "print(\"Number of validation examples:\", len(VAL_DATASET))\n",
    "print(\"Number of test examples:\", len(TEST_DATASET))\n",
    "\n",
    "#Data Loader 정의\n",
    "def collate_fn(batch):\n",
    "    # DETR authors employ various image sizes during training, making it not possible \n",
    "    # to directly batch together images. Hence they pad the images to the biggest \n",
    "    # resolution in a given batch, and create a corresponding binary pixel_mask \n",
    "    # which indicates which pixels are real/which are padding\n",
    "    pixel_values = [item[0] for item in batch]\n",
    "    encoding = image_processor.pad(pixel_values, return_tensors=\"pt\")\n",
    "    labels = [item[1] for item in batch]\n",
    "    return {\n",
    "        'pixel_values': encoding['pixel_values'],\n",
    "        'pixel_mask': encoding['pixel_mask'],\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "TRAIN_DATALOADER = DataLoader(dataset=TRAIN_DATASET, collate_fn=collate_fn, batch_size=4, num_workers=8, shuffle=True, pin_memory=True)\n",
    "VAL_DATALOADER = DataLoader(dataset=VAL_DATASET, collate_fn=collate_fn, batch_size=4, num_workers=8, pin_memory=True)\n",
    "TEST_DATALOADER = DataLoader(dataset=TEST_DATASET, collate_fn=collate_fn, batch_size=2, pin_memory=True)\n",
    "\n",
    "#DeTR Class 정의\n",
    "class Detr(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, lr=1e-4, lr_backbone=1e-5, weight_decay=1e-4):\n",
    "        super().__init__()\n",
    "        self.model = DetrForObjectDetection.from_pretrained(\n",
    "            pretrained_model_name_or_path = CHECKPOINT,\n",
    "            revision = 'no_timm',\n",
    "            num_labels = 10,\n",
    "            ignore_mismatched_sizes = True\n",
    "        )\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.lr_backbone = lr_backbone\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    # def forward(self, pixel_values, pixel_mask):\n",
    "    #     return self.model(pixel_values=pixel_values, pixel_mask=pixel_mask)\n",
    "\n",
    "    # def common_step(self, batch, batch_idx):\n",
    "    #     pixel_values = batch[\"pixel_values\"]\n",
    "    #     pixel_mask = batch[\"pixel_mask\"]\n",
    "    #     labels = [{k: v.to(self.device) for k, v in t.items()} for t in batch[\"labels\"]]\n",
    "\n",
    "    #     outputs = self.model(pixel_values=pixel_values, pixel_mask=pixel_mask, labels=labels)\n",
    "\n",
    "    #     loss = outputs.loss\n",
    "    #     loss_dict = outputs.loss_dict\n",
    "  \n",
    "    #     return loss, loss_dict\n",
    "\n",
    "    # def training_step(self, batch, batch_idx):\n",
    "    #     loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "    #     # logs metrics for each training_step, and the average across the epoch\n",
    "    #     self.log(\"training_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "    #     for k,v in loss_dict.items():\n",
    "    #         self.log(\"train_\" + k, v.item())\n",
    "\n",
    "    #     return loss\n",
    "\n",
    "    # def validation_step(self, batch, batch_idx):    \n",
    "    #     loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "    #     self.log(\"validation/loss\", loss,on_step=True, on_epoch=True, logger=True)\n",
    "    #     for k, v in loss_dict.items():\n",
    "    #         self.log(\"validation_\" + k, v.item())\n",
    "\n",
    "    #     return loss\n",
    "\n",
    "    # def test_step(self, batch, batch_idx):\n",
    "    #     loss, loss_dict = self.common_step(batch, batch_idx)\n",
    "    #     # logs metrics for each training_step, and the average across the epoch\n",
    "    #     self.log(\"test_loss\", loss, on_step=True, on_epoch=True, logger=True)\n",
    "    #     for k,v in loss_dict.items():\n",
    "    #         self.log(\"test_\" + k, v.item())\n",
    "\n",
    "    #     return loss\n",
    "\n",
    "    # def configure_optimizers(self):\n",
    "    #     # DETR authors decided to use different learning rate for backbone\n",
    "    #     # you can learn more about it here:\n",
    "    #     # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L22-L23\n",
    "    #     # - https://github.com/facebookresearch/detr/blob/3af9fa878e73b6894ce3596450a8d9b89d918ca9/main.py#L131-L139\n",
    "    #     param_dicts = [\n",
    "    #         {\n",
    "    #             \"params\": [p for n, p in self.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "    #         {\n",
    "    #             \"params\": [p for n, p in self.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "    #             \"lr\": self.lr_backbone,\n",
    "    #         },\n",
    "    #     ]\n",
    "    #     return torch.optim.AdamW(param_dicts, lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return TRAIN_DATALOADER\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return VAL_DATALOADER\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return TEST_DATALOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DetrForObjectDetection were not initialized from the model checkpoint at facebook/detr-resnet-50 and are newly initialized because the shapes did not match:\n",
      "- class_labels_classifier.weight: found shape torch.Size([92, 256]) in the checkpoint and torch.Size([11, 256]) in the model instantiated\n",
      "- class_labels_classifier.bias: found shape torch.Size([92]) in the checkpoint and torch.Size([11]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = \"../DeTR-Compare_frozen_layers/DeTR-Compare frozen layers/backbone+attention/checkpoints/epoch=4-step=24245.ckpt\"\n",
    "\n",
    "model = Detr.load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet에서 DeTR로 Weights and Biases 값 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n",
      "Detr(\n",
      "  (model): DetrForObjectDetection(\n",
      "    (model): DetrModel(\n",
      "      (backbone): DetrConvModel(\n",
      "        (conv_encoder): DetrConvEncoder(\n",
      "          (model): ResNetBackbone(\n",
      "            (embedder): ResNetEmbeddings(\n",
      "              (embedder): ResNetConvLayer(\n",
      "                (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "                (normalization): DetrFrozenBatchNorm2d()\n",
      "                (activation): ReLU()\n",
      "              )\n",
      "              (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "            )\n",
      "            (encoder): ResNetEncoder(\n",
      "              (stages): ModuleList(\n",
      "                (0): ResNetStage(\n",
      "                  (layers): Sequential(\n",
      "                    (0): ResNetBottleNeckLayer(\n",
      "                      (shortcut): ResNetShortCut(\n",
      "                        (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                        (normalization): DetrFrozenBatchNorm2d()\n",
      "                      )\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (1): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (2): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (1): ResNetStage(\n",
      "                  (layers): Sequential(\n",
      "                    (0): ResNetBottleNeckLayer(\n",
      "                      (shortcut): ResNetShortCut(\n",
      "                        (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                        (normalization): DetrFrozenBatchNorm2d()\n",
      "                      )\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (1): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (2): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (3): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (2): ResNetStage(\n",
      "                  (layers): Sequential(\n",
      "                    (0): ResNetBottleNeckLayer(\n",
      "                      (shortcut): ResNetShortCut(\n",
      "                        (convolution): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                        (normalization): DetrFrozenBatchNorm2d()\n",
      "                      )\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (1): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (2): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (3): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (4): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (5): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "                (3): ResNetStage(\n",
      "                  (layers): Sequential(\n",
      "                    (0): ResNetBottleNeckLayer(\n",
      "                      (shortcut): ResNetShortCut(\n",
      "                        (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                        (normalization): DetrFrozenBatchNorm2d()\n",
      "                      )\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (1): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                    (2): ResNetBottleNeckLayer(\n",
      "                      (shortcut): Identity()\n",
      "                      (layer): Sequential(\n",
      "                        (0): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (1): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): ReLU()\n",
      "                        )\n",
      "                        (2): ResNetConvLayer(\n",
      "                          (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                          (normalization): DetrFrozenBatchNorm2d()\n",
      "                          (activation): Identity()\n",
      "                        )\n",
      "                      )\n",
      "                      (activation): ReLU()\n",
      "                    )\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (position_embedding): DetrSinePositionEmbedding()\n",
      "      )\n",
      "      (input_projection): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (query_position_embeddings): Embedding(100, 256)\n",
      "      (encoder): DetrEncoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-5): 6 x DetrEncoderLayer(\n",
      "            (self_attn): DetrAttention(\n",
      "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (activation_fn): ReLU()\n",
      "            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (decoder): DetrDecoder(\n",
      "        (layers): ModuleList(\n",
      "          (0-5): 6 x DetrDecoderLayer(\n",
      "            (self_attn): DetrAttention(\n",
      "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (activation_fn): ReLU()\n",
      "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (encoder_attn): DetrAttention(\n",
      "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            )\n",
      "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
      "            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
      "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (class_labels_classifier): Linear(in_features=256, out_features=11, bias=True)\n",
      "    (bbox_predictor): DetrMLPPredictionHead(\n",
      "      (layers): ModuleList(\n",
      "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
      "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(finetuned_resnet)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# finetune한 Layer4 불러오기\n",
    "finetuned_layer4 = finetuned_resnet.layer4\n",
    "print(finetuned_layer4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNetStage(\n",
      "  (layers): Sequential(\n",
      "    (0): ResNetBottleNeckLayer(\n",
      "      (shortcut): ResNetShortCut(\n",
      "        (convolution): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (normalization): DetrFrozenBatchNorm2d()\n",
      "      )\n",
      "      (layer): Sequential(\n",
      "        (0): ResNetConvLayer(\n",
      "          (convolution): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): DetrFrozenBatchNorm2d()\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (1): ResNetConvLayer(\n",
      "          (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (normalization): DetrFrozenBatchNorm2d()\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (2): ResNetConvLayer(\n",
      "          (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): DetrFrozenBatchNorm2d()\n",
      "          (activation): Identity()\n",
      "        )\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (1): ResNetBottleNeckLayer(\n",
      "      (shortcut): Identity()\n",
      "      (layer): Sequential(\n",
      "        (0): ResNetConvLayer(\n",
      "          (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): DetrFrozenBatchNorm2d()\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (1): ResNetConvLayer(\n",
      "          (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (normalization): DetrFrozenBatchNorm2d()\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (2): ResNetConvLayer(\n",
      "          (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): DetrFrozenBatchNorm2d()\n",
      "          (activation): Identity()\n",
      "        )\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "    (2): ResNetBottleNeckLayer(\n",
      "      (shortcut): Identity()\n",
      "      (layer): Sequential(\n",
      "        (0): ResNetConvLayer(\n",
      "          (convolution): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): DetrFrozenBatchNorm2d()\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (1): ResNetConvLayer(\n",
      "          (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (normalization): DetrFrozenBatchNorm2d()\n",
      "          (activation): ReLU()\n",
      "        )\n",
      "        (2): ResNetConvLayer(\n",
      "          (convolution): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (normalization): DetrFrozenBatchNorm2d()\n",
      "          (activation): Identity()\n",
      "        )\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "# DeTR backbone의 Layer4 불러오기 (ResNetStage3)\n",
    "resnetstage3 = model.model.model.backbone.conv_encoder.model.encoder.stages[3]\n",
    "print(resnetstage3)\n",
    "print(resnetstage3.layers[0].layer[0].normalization.bias.data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottleneck(\n",
      "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# (0) Bottleneck from finetuned_layer4\n",
    "finetuned_layer4_bottleneck = list(finetuned_layer4.children())\n",
    "#print(finetuned_layer4_bottleneck)\n",
    "#print(finetuned_layer4_bottleneck[0].bn1.weight.data.size())\n",
    "print(finetuned_layer4_bottleneck[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNetStage3.layers0.layer0.convolution size = [512,1024,1,1]\n",
    "resnetstage3.layers[0].layer[0].convolution.weight.data = finetuned_layer4_bottleneck[0].conv1.weight.data.clone()\n",
    "#print(resnetstage3.layers[0].layer[0].convolution.weight.data)\n",
    "#print(model.model.model.backbone.conv_encoder.model.encoder.stages[3].layers[0].layer[0].convolution.weight.data)\n",
    "\n",
    "# ResNetStage3.layers0.layer1.convolution size = [512,612,3,3]\n",
    "resnetstage3.layers[0].layer[1].convolution.weight.data = finetuned_layer4_bottleneck[0].conv2.weight.data.clone()\n",
    "\n",
    "# ResNetStage3.layers0.layer2.convolution size = [2048,512,1,1]\n",
    "resnetstage3.layers[0].layer[2].convolution.weight.data = finetuned_layer4_bottleneck[0].conv3.weight.data.clone()\n",
    "\n",
    "# ResNEtStage3.layers1.layer0.convolution size = [512,2048,1,1]\n",
    "resnetstage3.layers[1].layer[0].convolution.weight.data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    finetuned_block = finetuned_layer4_bottleneck[i]\n",
    "    detr_block = resnetstage3.layers[i]\n",
    "\n",
    "    # Weights for convolution layers\n",
    "    detr_block.layer[0].convolution.weight.data = finetuned_block.conv1.weight.data.clone()\n",
    "    detr_block.layer[1].convolution.weight.data = finetuned_block.conv2.weight.data.clone()\n",
    "    detr_block.layer[2].convolution.weight.data = finetuned_block.conv3.weight.data.clone()\n",
    "\n",
    "    # Weights and Biases for normalization layers\n",
    "    detr_block.layer[0].normalization.weight.data = finetuned_block.bn1.weight.data.clone()\n",
    "    detr_block.layer[0].normalization.bias.data = finetuned_block.bn1.bias.data.clone()\n",
    "    detr_block.layer[1].normalization.weight.data = finetuned_block.bn2.weight.data.clone()\n",
    "    detr_block.layer[1].normalization.bias.data = finetuned_block.bn2.bias.data.clone()\n",
    "    detr_block.layer[2].normalization.weight.data = finetuned_block.bn3.weight.data.clone()\n",
    "    detr_block.layer[2].normalization.bias.data = finetuned_block.bn3.bias.data.clone()\n",
    "\n",
    "# Weights for ResNetShortCut.convolution layer\n",
    "resnetstage3.layers[0].shortcut.convolution.weight.data = finetuned_layer4_bottleneck[0].downsample[0].weight.data.clone()\n",
    "\n",
    "# Weights and Biases for ResNetShortCut.normalization layer\n",
    "resnetstage3.layers[0].shortcut.normalization.weight.data = finetuned_layer4_bottleneck[0].downsample[1].weight.data.clone()\n",
    "resnetstage3.layers[0].shortcut.normalization.bias.data = finetuned_layer4_bottleneck[0].downsample[1].bias.data.clone()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7504, 0.8020, 0.9884,  ..., 0.8470, 0.9360, 0.8504])\n",
      "tensor([0.7504, 0.8020, 0.9884,  ..., 0.8470, 0.9360, 0.8504])\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(model.model.model.backbone.conv_encoder.model.encoder.stages[3].layers[0].shortcut.normalization.weight.data)\n",
    "print(finetuned_layer4_bottleneck[0].downsample[1].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbone 변경된 모델 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../Models/DeTR_with_ResNet_RoI.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
