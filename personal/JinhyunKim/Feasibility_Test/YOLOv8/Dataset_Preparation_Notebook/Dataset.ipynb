{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83168518-57e0-42bc-96e2-af1d86303537",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dataset 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Downloading Custom Labeled Data from Roboflow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3b86083f3ec7ff2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.9-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: certifi==2023.7.22 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (2023.7.22)\n",
      "Collecting chardet==4.0.0 (from roboflow)\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "     ---------------------------------------- 0.0/178.7 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/178.7 kB ? eta -:--:--\n",
      "     -------------------------------------- 178.7/178.7 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting cycler==0.10.0 (from roboflow)\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting idna==2.10 (from roboflow)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "     ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 58.8/58.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (1.26.1)\n",
      "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (10.0.1)\n",
      "Collecting pyparsing==2.4.7 (from roboflow)\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "     ---------------------------------------- 0.0/67.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 67.8/67.8 kB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (2.31.0)\n",
      "Requirement already satisfied: six in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Collecting supervision (from roboflow)\n",
      "  Downloading supervision-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (1.26.18)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from roboflow) (6.0.1)\n",
      "Collecting requests-toolbelt (from roboflow)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting python-magic (from roboflow)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from matplotlib->roboflow) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from matplotlib->roboflow) (4.44.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from matplotlib->roboflow) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from requests->roboflow) (3.3.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in c:\\users\\jhk16\\pycharmprojects\\wise_ad-\\venv\\lib\\site-packages (from supervision->roboflow) (1.11.3)\n",
      "Downloading roboflow-1.1.9-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.3/63.3 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading opencv_python_headless-4.8.0.74-cp37-abi3-win_amd64.whl (38.0 MB)\n",
      "   ---------------------------------------- 0.0/38.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.6/38.0 MB 34.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 3.1/38.0 MB 40.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 4.9/38.0 MB 35.1 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 7.8/38.0 MB 41.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 10.7/38.0 MB 46.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 13.6/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 16.6/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 19.5/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 22.4/38.0 MB 59.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 25.3/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.3/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.2/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.0/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 36.9/38.0 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  37.9/38.0 MB 59.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.0/38.0 MB 50.4 MB/s eta 0:00:00\n",
      "Downloading supervision-0.16.0-py3-none-any.whl (72 kB)\n",
      "   ---------------------------------------- 0.0/72.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 72.2/72.2 kB ? eta 0:00:00\n",
      "Installing collected packages: python-magic, python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, supervision, requests-toolbelt, roboflow\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.1.1\n",
      "    Uninstalling pyparsing-3.1.1:\n",
      "      Successfully uninstalled pyparsing-3.1.1\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.8.1.78\n",
      "    Uninstalling opencv-python-headless-4.8.1.78:\n",
      "      Successfully uninstalled opencv-python-headless-4.8.1.78\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.12.1\n",
      "    Uninstalling cycler-0.12.1:\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "Successfully installed chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.9 supervision-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T01:57:40.474007Z",
     "start_time": "2023-11-22T01:57:32.996478400Z"
    }
   },
   "id": "f0ea0625039009a5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.215, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Coupang_Sweatshirt_2000-5 to yolov8:: 100%|██████████| 83206/83206 [00:04<00:00, 18279.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Coupang_Sweatshirt_2000-5 in yolov8:: 100%|██████████| 5626/5626 [00:02<00:00, 1963.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Coupang Dataset for YOLOv8\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"rYBl8XHVMjJdpPIT67zF\")\n",
    "project = rf.workspace(\"inisw91\").project(\"coupang_sweatshirt_2000\")\n",
    "dataset = project.version(5).download(\"yolov8\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T01:59:02.196604300Z",
     "start_time": "2023-11-22T01:58:40.753918Z"
    }
   },
   "id": "ab38f1f2e89ab1d5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.0.215, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Sweatshirts_youtube-2 to yolov8:: 100%|██████████| 56495/56495 [00:02<00:00, 25018.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Sweatshirts_youtube-2 in yolov8:: 100%|██████████| 3206/3206 [00:01<00:00, 1955.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Youtube Dataset for YOLOv8\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"El60cQAWYQvZ269ZDtRd\")\n",
    "project = rf.workspace(\"project-9yric\").project(\"sweatshirts_youtube\")\n",
    "dataset = project.version(2).download(\"yolov8\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T02:27:10.763621500Z",
     "start_time": "2023-11-22T02:27:00.898957100Z"
    }
   },
   "id": "8a632513f6d84b75"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Merging Datasets with Fiftyone"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1acd35fd4c97739e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install fiftyone"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3087182d4d0ac03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2-1. Coupang + Youtube"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7137bd382260bd8f"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 1914/1914 [1.9s elapsed, 0s remaining, 1.0K samples/s]       \n",
      " 100% |█████████████████| 295/295 [285.4ms elapsed, 0s remaining, 1.0K samples/s]      \n",
      " 100% |█████████████████| 598/598 [547.5ms elapsed, 0s remaining, 1.1K samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "\n",
    "# Initialize the main dataset\n",
    "name = \"Coupang+Youtube_4thtry\"\n",
    "dataset = fo.Dataset(name)\n",
    "\n",
    "# Load and tag the first dataset\n",
    "dataset_dir = \"D:/Data/Coupang_Sweatshirt_2000-5\"\n",
    "splits = [\"train\", \"test\", \"val\"]\n",
    "for split in splits:\n",
    "    dataset.add_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=[split]\n",
    "    )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T03:13:33.102558600Z",
     "start_time": "2023-11-22T03:13:29.425764Z"
    }
   },
   "id": "a73b9118909e189a"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 1109/1109 [1.3s elapsed, 0s remaining, 879.7 samples/s]         \n",
      " 100% |█████████████████| 164/164 [187.0ms elapsed, 0s remaining, 877.2 samples/s]     \n",
      " 100% |█████████████████| 324/324 [352.2ms elapsed, 0s remaining, 920.0 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Load and tag the second dataset into a separate Dataset object\n",
    "dataset_dir2 = \"D:/Data/Sweatshirts_youtube-2\"\n",
    "for split in splits:\n",
    "    dataset.merge_dir(\n",
    "        dataset_dir = dataset_dir2,\n",
    "        dataset_type = fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=[split],\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T03:18:58.395371300Z",
     "start_time": "2023-11-22T03:18:55.869804500Z"
    }
   },
   "id": "4de5387f7bcc4a88"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'D:/Data/sweatshirts_final' already exists; export will be merged with existing files\n",
      " 100% |███████████████| 3023/3023 [36.7s elapsed, 0s remaining, 146.8 samples/s]      \n",
      "Directory 'D:/Data/sweatshirts_final' already exists; export will be merged with existing files\n",
      " 100% |█████████████████| 459/459 [7.6s elapsed, 0s remaining, 89.1 samples/s]       \n",
      "Directory 'D:/Data/sweatshirts_final' already exists; export will be merged with existing files\n",
      " 100% |█████████████████| 922/922 [10.8s elapsed, 0s remaining, 148.0 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Export each split\n",
    "export_dir = \"D:/Data/sweatshirts_final\"\n",
    "for split in splits:\n",
    "    split_view = dataset.match(fo.ViewField(\"tags\").contains(split))\n",
    "    split_view.export(\n",
    "        export_dir=export_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split\n",
    "    )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T03:20:25.306450Z",
     "start_time": "2023-11-22T03:19:30.149291300Z"
    }
   },
   "id": "7ec55f9108f0cf2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2-2. Load and Export OpenImages V7"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b6d8896a5302720"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1) Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f13d3fe277b8166"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading class: Bowl\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 1464 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-bowl-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 1464/1464 [7.8s elapsed, 0s remaining, 194.6 samples/s]       \n",
      "Loading class: Backpack\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 715 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-backpack-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 715/715 [3.2s elapsed, 0s remaining, 231.6 samples/s]      \n",
      "Loading class: Laptop\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-laptop-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 5000/5000 [26.3s elapsed, 0s remaining, 203.6 samples/s]      \n",
      "Loading class: Oven\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 509 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-oven-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 509/509 [2.9s elapsed, 0s remaining, 185.0 samples/s]      \n",
      "Loading class: Toaster\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 60 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-toaster-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 60/60 [174.5ms elapsed, 0s remaining, 347.7 samples/s]    \n",
      "Loading class: Mouse\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 698 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-mouse-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 698/698 [1.3s elapsed, 0s remaining, 550.8 samples/s]         \n",
      "Loading class: Bottle\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-bottle-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 5000/5000 [31.4s elapsed, 0s remaining, 155.8 samples/s]      \n",
      "Loading class: Tennis racket\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 807 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-tennis-racket-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 807/807 [3.1s elapsed, 0s remaining, 246.2 samples/s]      \n",
      "Loading class: Clock\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 916 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-clock-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 916/916 [2.7s elapsed, 0s remaining, 331.0 samples/s]      \n",
      "Loading class: Tie\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-tie-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 5000/5000 [28.4s elapsed, 0s remaining, 173.3 samples/s]      \n",
      "Loading class: Wine glass\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 4894 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-wine-glass-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 4894/4894 [35.6s elapsed, 0s remaining, 136.1 samples/s]      \n",
      "Loading class: Spoon\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 1044 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-spoon-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 1044/1044 [3.7s elapsed, 0s remaining, 286.3 samples/s]      \n",
      "Loading class: Scissors\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 292 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-scissors-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 292/292 [500.8ms elapsed, 0s remaining, 585.3 samples/s]      \n",
      "Loading class: Toothbrush\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 113 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-toothbrush-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 113/113 [229.6ms elapsed, 0s remaining, 495.9 samples/s]     \n",
      "Loading class: Refrigerator\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 549 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-refrigerator-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 549/549 [2.4s elapsed, 0s remaining, 247.7 samples/s]      \n",
      "Loading class: Couch\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 3321 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-couch-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 3321/3321 [21.1s elapsed, 0s remaining, 170.0 samples/s]      \n",
      "Loading class: Chair\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-chair-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 5000/5000 [49.5s elapsed, 0s remaining, 106.3 samples/s]      \n",
      "Loading class: Umbrella\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 3357 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-umbrella-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 3357/3357 [25.1s elapsed, 0s remaining, 143.1 samples/s]      \n",
      "Loading class: Knife\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 610 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-knife-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 610/610 [1.3s elapsed, 0s remaining, 455.5 samples/s]         \n",
      "Loading class: Suitcase\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Only found 408 (<5000) samples matching your requirements\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-suitcase-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 408/408 [1.6s elapsed, 0s remaining, 258.7 samples/s]         \n",
      "Loading class: Sunglasses\n",
      "Downloading split 'train' to 'D://Data\\open-images-v7\\train' if necessary\n",
      "Necessary images already downloaded\n",
      "Existing download of split 'train' is sufficient\n",
      "Loading existing dataset 'open-images-v7-sunglasses-train'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████| 5000/5000 [41.5s elapsed, 0s remaining, 127.0 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import os\n",
    "\n",
    "\n",
    "classes = [\n",
    "    \"Bowl\", \"Backpack\", \"Laptop\", \"Oven\", \"Toaster\", \"Mouse\", \"Bottle\",\n",
    "    \"Tennis racket\", \"Clock\", \"Tie\", \"Wine glass\", \"Spoon\", \"Scissors\",\n",
    "    \"Toothbrush\", \"Refrigerator\", \"Couch\", \"Chair\", \"Umbrella\", \"Knife\",\n",
    "    \"Suitcase\", \"Sunglasses\"\n",
    "]\n",
    "\n",
    "# Specify your custom download directory\n",
    "dataset_dir = \"D://Data\"  # Replace with your desired path\n",
    "\n",
    "# Set the base data directory for FiftyOne\n",
    "fo.config.dataset_zoo_dir = dataset_dir\n",
    "\n",
    "# Create an empty dataset\n",
    "accumulated_dataset = fo.Dataset()\n",
    "\n",
    "for cls in classes:\n",
    "    print(f\"Loading class: {cls}\")\n",
    "\n",
    "    # Generate a unique dataset name for each class\n",
    "    dataset_name = f\"open-images-v7-{cls.lower().replace(' ', '-')}-train\"\n",
    "\n",
    "    dataset = foz.load_zoo_dataset(\n",
    "        \"open-images-v7\",\n",
    "        split=\"train\",\n",
    "        classes=[cls],\n",
    "        label_types=[\"detections\"],\n",
    "        max_samples=5000,\n",
    "        seed=51,\n",
    "        shuffle=True,\n",
    "        dataset_name=dataset_name  # Use the unique dataset name here\n",
    "    )\n",
    "\n",
    "    # Add samples to the accumulated dataset\n",
    "    accumulated_dataset.add_samples(dataset)\n",
    "\n",
    "# # 축적된 데이터셋 저장\n",
    "# accumulated_dataset.persistent = True\n",
    "# accumulated_dataset_name = \"accumulated_openimages_dataset\"\n",
    "# accumulated_dataset.save(accumulated_dataset_name)\n",
    "# print(f\"데이터셋 '{accumulated_dataset_name}' 저장 완료.\")\n",
    "\n",
    "# Now `accumulated_dataset` contains all the data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:04:56.078161300Z",
     "start_time": "2023-11-22T14:58:44.246325300Z"
    }
   },
   "id": "f32f791ea65db4f9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "view = accumulated_dataset.filter_labels(\"ground_truth\", \n",
    "                             fo.ViewField(\"label\").is_in(classes))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:05:20.521463300Z",
     "start_time": "2023-11-22T16:05:20.518455800Z"
    }
   },
   "id": "598e264a81e6a234"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'D://Data//open-images-v7' already exists; export will be merged with existing files\n",
      " 100% |█████████████| 44757/44757 [23.4m elapsed, 0s remaining, 28.5 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Export the dataset in YOLOv5 format\n",
    "view.export(\n",
    "    export_dir=\"D://Data//open-images-v7\",  # Replace with your desired path\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    split=\"train\",  # You can specify the split (train, val, test) if needed\n",
    "    classes=classes\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:28:51.835163300Z",
     "start_time": "2023-11-22T16:05:27.344824900Z"
    }
   },
   "id": "bcdad7624df1bc38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2) Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2408cf205362f1b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading class: Bowl\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to 'D://Data\\open-images-v7\\validation\\metadata\\image_ids.csv'\n",
      "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to 'D://Data\\open-images-v7\\validation\\metadata\\classes.csv'\n",
      "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to 'C:\\Users\\jhk16\\AppData\\Local\\Temp\\tmpya_fd5lx\\metadata\\hierarchy.json'\n",
      "Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv' to 'D://Data\\open-images-v7\\validation\\labels\\detections.csv'\n",
      "Only found 49 (<922) samples matching your requirements\n",
      "Downloading 49 images\n",
      " 100% |█████████████████████| 49/49 [7.1s elapsed, 0s remaining, 6.8 files/s]       \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-bowl-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 49/49 [254.3ms elapsed, 0s remaining, 192.7 samples/s]     \n",
      "Loading class: Backpack\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 24 (<922) samples matching your requirements\n",
      "Downloading 24 images\n",
      " 100% |█████████████████████| 24/24 [5.8s elapsed, 0s remaining, 4.1 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-backpack-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 24/24 [85.9ms elapsed, 0s remaining, 279.5 samples/s]    \n",
      "Loading class: Laptop\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 52 (<922) samples matching your requirements\n",
      "Downloading 52 images\n",
      " 100% |█████████████████████| 52/52 [4.8s elapsed, 0s remaining, 33.0 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-laptop-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 52/52 [258.7ms elapsed, 0s remaining, 202.2 samples/s]      \n",
      "Loading class: Oven\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 35 (<922) samples matching your requirements\n",
      "Downloading 35 images\n",
      " 100% |█████████████████████| 35/35 [5.5s elapsed, 0s remaining, 11.5 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-oven-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 35/35 [216.3ms elapsed, 0s remaining, 161.8 samples/s]     \n",
      "Loading class: Toaster\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 1 (<922) samples matching your requirements\n",
      "Downloading 1 images\n",
      " 100% |███████████████████████| 1/1 [1.8s elapsed, 0s remaining, 0.6 files/s] \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-toaster-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████████| 1/1 [8.3ms elapsed, 0s remaining, 150.2 samples/s] \n",
      "Loading class: Mouse\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 45 (<922) samples matching your requirements\n",
      "Downloading 45 images\n",
      " 100% |█████████████████████| 45/45 [4.6s elapsed, 0s remaining, 35.2 files/s]     \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-mouse-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 45/45 [99.9ms elapsed, 0s remaining, 450.6 samples/s]     \n",
      "Loading class: Bottle\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 207 (<922) samples matching your requirements\n",
      "Downloading 207 images\n",
      " 100% |███████████████████| 207/207 [12.4s elapsed, 0s remaining, 13.6 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-bottle-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 207/207 [1.1s elapsed, 0s remaining, 184.3 samples/s]         \n",
      "Loading class: Tennis racket\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 24 (<922) samples matching your requirements\n",
      "Downloading 24 images\n",
      " 100% |█████████████████████| 24/24 [4.2s elapsed, 0s remaining, 5.8 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-tennis-racket-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 24/24 [192.2ms elapsed, 0s remaining, 126.1 samples/s]    \n",
      "Loading class: Clock\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 21 (<922) samples matching your requirements\n",
      "Downloading 21 images\n",
      " 100% |█████████████████████| 21/21 [5.0s elapsed, 0s remaining, 9.1 files/s]       \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-clock-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 21/21 [75.3ms elapsed, 0s remaining, 278.8 samples/s]    \n",
      "Loading class: Tie\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 97 (<922) samples matching your requirements\n",
      "Downloading 97 images\n",
      " 100% |█████████████████████| 97/97 [6.1s elapsed, 0s remaining, 30.0 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-tie-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 97/97 [745.9ms elapsed, 0s remaining, 130.4 samples/s]      \n",
      "Loading class: Wine glass\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 90 (<922) samples matching your requirements\n",
      "Found 19 images, downloading the remaining 71\n",
      " 100% |█████████████████████| 71/71 [7.5s elapsed, 0s remaining, 9.3 files/s]       \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-wine-glass-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 90/90 [699.1ms elapsed, 0s remaining, 128.7 samples/s]      \n",
      "Loading class: Spoon\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 52 (<922) samples matching your requirements\n",
      "Found 1 images, downloading the remaining 51\n",
      " 100% |█████████████████████| 51/51 [4.6s elapsed, 0s remaining, 36.1 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-spoon-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 52/52 [259.5ms elapsed, 0s remaining, 201.6 samples/s]     \n",
      "Loading class: Scissors\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 1 (<922) samples matching your requirements\n",
      "Downloading 1 images\n",
      " 100% |███████████████████████| 1/1 [2.2s elapsed, 0s remaining, 0.5 files/s] \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-scissors-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████████| 1/1 [3.6ms elapsed, 0s remaining, 476.0 samples/s] \n",
      "Loading class: Toothbrush\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 10 (<922) samples matching your requirements\n",
      "Downloading 10 images\n",
      " 100% |█████████████████████| 10/10 [5.0s elapsed, 0s remaining, 2.0 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-toothbrush-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 10/10 [25.5ms elapsed, 0s remaining, 391.8 samples/s]    \n",
      "Loading class: Refrigerator\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 25 (<922) samples matching your requirements\n",
      "Found 6 images, downloading the remaining 19\n",
      " 100% |█████████████████████| 19/19 [4.0s elapsed, 0s remaining, 4.8 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-refrigerator-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 25/25 [174.2ms elapsed, 0s remaining, 145.0 samples/s]    \n",
      "Loading class: Couch\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 49 (<922) samples matching your requirements\n",
      "Found 2 images, downloading the remaining 47\n",
      " 100% |█████████████████████| 47/47 [7.1s elapsed, 0s remaining, 5.2 files/s]       \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-couch-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 49/49 [530.3ms elapsed, 0s remaining, 92.7 samples/s]       \n",
      "Loading class: Chair\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 311 (<922) samples matching your requirements\n",
      "Found 23 images, downloading the remaining 288\n",
      " 100% |███████████████████| 288/288 [11.5s elapsed, 0s remaining, 18.4 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-chair-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 311/311 [3.6s elapsed, 0s remaining, 90.3 samples/s]      \n",
      "Loading class: Umbrella\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 27 (<922) samples matching your requirements\n",
      "Downloading 27 images\n",
      " 100% |█████████████████████| 27/27 [4.8s elapsed, 0s remaining, 5.7 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-umbrella-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 27/27 [211.6ms elapsed, 0s remaining, 127.6 samples/s]     \n",
      "Loading class: Knife\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 59 (<922) samples matching your requirements\n",
      "Downloading 59 images\n",
      " 100% |█████████████████████| 59/59 [6.4s elapsed, 0s remaining, 13.7 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-knife-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 59/59 [189.4ms elapsed, 0s remaining, 314.4 samples/s]    \n",
      "Loading class: Suitcase\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 23 (<922) samples matching your requirements\n",
      "Found 3 images, downloading the remaining 20\n",
      " 100% |█████████████████████| 20/20 [6.6s elapsed, 0s remaining, 5.2 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-suitcase-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |███████████████████| 23/23 [78.0ms elapsed, 0s remaining, 294.8 samples/s]    \n",
      "Loading class: Sunglasses\n",
      "Downloading split 'validation' to 'D://Data\\open-images-v7\\validation' if necessary\n",
      "Only found 134 (<922) samples matching your requirements\n",
      "Found 3 images, downloading the remaining 131\n",
      " 100% |███████████████████| 131/131 [9.9s elapsed, 0s remaining, 9.6 files/s]       \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading existing dataset 'open-images-v7-sunglasses-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n",
      " 100% |█████████████████| 134/134 [2.3s elapsed, 0s remaining, 56.4 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import os\n",
    "\n",
    "\n",
    "classes = [\n",
    "    \"Bowl\", \"Backpack\", \"Laptop\", \"Oven\", \"Toaster\", \"Mouse\", \"Bottle\",\n",
    "    \"Tennis racket\", \"Clock\", \"Tie\", \"Wine glass\", \"Spoon\", \"Scissors\",\n",
    "    \"Toothbrush\", \"Refrigerator\", \"Couch\", \"Chair\", \"Umbrella\", \"Knife\",\n",
    "    \"Suitcase\", \"Sunglasses\"\n",
    "]\n",
    "\n",
    "# Specify your custom download directory\n",
    "dataset_dir = \"D://Data\"  # Replace with your desired path\n",
    "\n",
    "# Set the base data directory for FiftyOne\n",
    "fo.config.dataset_zoo_dir = dataset_dir\n",
    "\n",
    "# Create an empty dataset\n",
    "accumulated_dataset = fo.Dataset()\n",
    "\n",
    "for cls in classes:\n",
    "    print(f\"Loading class: {cls}\")\n",
    "\n",
    "    # Generate a unique dataset name for each class\n",
    "    dataset_name = f\"open-images-v7-{cls.lower().replace(' ', '-')}-validation\"\n",
    "\n",
    "    dataset = foz.load_zoo_dataset(\n",
    "        \"open-images-v7\",\n",
    "        split=\"validation\",\n",
    "        classes=[cls],\n",
    "        label_types=[\"detections\"],\n",
    "        max_samples=922,\n",
    "        seed=51,\n",
    "        shuffle=True,\n",
    "        dataset_name=dataset_name  # Use the unique dataset name here\n",
    "    )\n",
    "\n",
    "    # Add samples to the accumulated dataset\n",
    "    accumulated_dataset.add_samples(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:33:46.041982700Z",
     "start_time": "2023-11-22T16:31:05.715619700Z"
    }
   },
   "id": "4bc6a36e2006245a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "accumulated_dataset.default_classes = classes\n",
    "view = accumulated_dataset.filter_labels(\"ground_truth\", \n",
    "                             fo.ViewField(\"label\").is_in(classes))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:34:00.835740500Z",
     "start_time": "2023-11-22T16:34:00.829223400Z"
    }
   },
   "id": "5cfeb1d6c76980ab"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'D://Data//open-images-v7' already exists; export will be merged with existing files\n",
      " 100% |███████████████| 1336/1336 [12.8s elapsed, 0s remaining, 153.7 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Export the dataset in YOLOv5 format\n",
    "view.export(\n",
    "    export_dir=\"D://Data//open-images-v7\",  # Replace with your desired path\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    split=\"val\",  # You can specify the split (train, val, test) if needed\n",
    "    classes=classes\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:34:27.375786300Z",
     "start_time": "2023-11-22T16:34:14.577234Z"
    }
   },
   "id": "7fa5ceb0df614a8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3) Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15f722ce388d9ed0"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading class: Bowl\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Downloading 'https://storage.googleapis.com/openimages/2018_04/test/test-images-with-rotation.csv' to 'D://Data\\open-images-v7\\test\\metadata\\image_ids.csv'\n",
      "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to 'D://Data\\open-images-v7\\test\\metadata\\classes.csv'\n",
      "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to 'C:\\Users\\jhk16\\AppData\\Local\\Temp\\tmpkwtp17m7\\metadata\\hierarchy.json'\n",
      "Downloading 'https://storage.googleapis.com/openimages/v5/test-annotations-bbox.csv' to 'D://Data\\open-images-v7\\test\\labels\\detections.csv'\n",
      "Only found 147 (<459) samples matching your requirements\n",
      "Downloading 147 images\n",
      " 100% |███████████████████| 147/147 [6.7s elapsed, 0s remaining, 44.0 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 147/147 [442.0ms elapsed, 0s remaining, 332.5 samples/s]      \n",
      "Dataset 'open-images-v7-bowl-test' created\n",
      " 100% |█████████████████| 147/147 [584.6ms elapsed, 0s remaining, 252.3 samples/s]      \n",
      "Loading class: Backpack\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 74 (<459) samples matching your requirements\n",
      "Downloading 74 images\n",
      " 100% |█████████████████████| 74/74 [7.6s elapsed, 0s remaining, 10.0 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |███████████████████| 74/74 [241.7ms elapsed, 0s remaining, 306.1 samples/s]     \n",
      "Dataset 'open-images-v7-backpack-test' created\n",
      " 100% |███████████████████| 74/74 [293.1ms elapsed, 0s remaining, 252.4 samples/s]      \n",
      "Loading class: Laptop\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 197 (<459) samples matching your requirements\n",
      "Downloading 197 images\n",
      " 100% |███████████████████| 197/197 [8.2s elapsed, 0s remaining, 33.8 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 197/197 [879.1ms elapsed, 0s remaining, 224.5 samples/s]      \n",
      "Dataset 'open-images-v7-laptop-test' created\n",
      " 100% |█████████████████| 197/197 [1.1s elapsed, 0s remaining, 177.9 samples/s]         \n",
      "Loading class: Oven\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 77 (<459) samples matching your requirements\n",
      "Downloading 77 images\n",
      " 100% |█████████████████████| 77/77 [5.9s elapsed, 0s remaining, 25.2 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |███████████████████| 77/77 [505.6ms elapsed, 0s remaining, 152.8 samples/s]      \n",
      "Dataset 'open-images-v7-oven-test' created\n",
      " 100% |███████████████████| 77/77 [541.5ms elapsed, 0s remaining, 142.6 samples/s]      \n",
      "Loading class: Toaster\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 4 (<459) samples matching your requirements\n",
      "Found 1 images, downloading the remaining 3\n",
      " 100% |███████████████████████| 3/3 [2.1s elapsed, 0s remaining, 1.4 files/s]   \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████████| 4/4 [31.2ms elapsed, 0s remaining, 128.1 samples/s]    \n",
      "Dataset 'open-images-v7-toaster-test' created\n",
      " 100% |█████████████████████| 4/4 [27.9ms elapsed, 0s remaining, 143.2 samples/s]   \n",
      "Loading class: Mouse\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 210 (<459) samples matching your requirements\n",
      "Found 1 images, downloading the remaining 209\n",
      " 100% |███████████████████| 209/209 [11.5s elapsed, 0s remaining, 11.4 files/s]     \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 210/210 [397.4ms elapsed, 0s remaining, 531.5 samples/s]      \n",
      "Dataset 'open-images-v7-mouse-test' created\n",
      " 100% |█████████████████| 210/210 [503.4ms elapsed, 0s remaining, 417.2 samples/s]      \n",
      "Loading class: Bottle\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Found 3 images, downloading the remaining 456\n",
      " 100% |███████████████████| 456/456 [14.2s elapsed, 0s remaining, 42.5 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 459/459 [1.8s elapsed, 0s remaining, 255.6 samples/s]      \n",
      "Dataset 'open-images-v7-bottle-test' created\n",
      " 100% |█████████████████| 459/459 [2.4s elapsed, 0s remaining, 190.7 samples/s]      \n",
      "Loading class: Tennis racket\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 104 (<459) samples matching your requirements\n",
      "Downloading 104 images\n",
      " 100% |███████████████████| 104/104 [10.2s elapsed, 0s remaining, 3.6 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 104/104 [770.8ms elapsed, 0s remaining, 135.3 samples/s]      \n",
      "Dataset 'open-images-v7-tennis-racket-test' created\n",
      " 100% |█████████████████| 104/104 [1.1s elapsed, 0s remaining, 92.9 samples/s]         \n",
      "Loading class: Clock\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 51 (<459) samples matching your requirements\n",
      "Downloading 51 images\n",
      " 100% |█████████████████████| 51/51 [6.9s elapsed, 0s remaining, 9.2 files/s]       \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |███████████████████| 51/51 [245.9ms elapsed, 0s remaining, 208.7 samples/s]    \n",
      "Dataset 'open-images-v7-clock-test' created\n",
      " 100% |███████████████████| 51/51 [183.0ms elapsed, 0s remaining, 281.3 samples/s]    \n",
      "Loading class: Tie\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 320 (<459) samples matching your requirements\n",
      "Found 2 images, downloading the remaining 318\n",
      " 100% |███████████████████| 318/318 [10.5s elapsed, 0s remaining, 46.4 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 320/320 [2.2s elapsed, 0s remaining, 157.0 samples/s]      \n",
      "Dataset 'open-images-v7-tie-test' created\n",
      " 100% |█████████████████| 320/320 [2.8s elapsed, 0s remaining, 116.2 samples/s]      \n",
      "Loading class: Wine glass\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 261 (<459) samples matching your requirements\n",
      "Found 33 images, downloading the remaining 228\n",
      " 100% |███████████████████| 228/228 [8.6s elapsed, 0s remaining, 44.2 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 261/261 [1.5s elapsed, 0s remaining, 168.6 samples/s]         \n",
      "Dataset 'open-images-v7-wine-glass-test' created\n",
      " 100% |█████████████████| 261/261 [2.1s elapsed, 0s remaining, 130.0 samples/s]      \n",
      "Loading class: Spoon\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 155 (<459) samples matching your requirements\n",
      "Found 6 images, downloading the remaining 149\n",
      " 100% |███████████████████| 149/149 [7.0s elapsed, 0s remaining, 39.5 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 155/155 [506.4ms elapsed, 0s remaining, 306.1 samples/s]      \n",
      "Dataset 'open-images-v7-spoon-test' created\n",
      " 100% |█████████████████| 155/155 [643.3ms elapsed, 0s remaining, 241.6 samples/s]      \n",
      "Loading class: Scissors\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 6 (<459) samples matching your requirements\n",
      "Downloading 6 images\n",
      " 100% |███████████████████████| 6/6 [2.8s elapsed, 0s remaining, 2.1 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████████| 6/6 [24.2ms elapsed, 0s remaining, 248.2 samples/s]    \n",
      "Dataset 'open-images-v7-scissors-test' created\n",
      " 100% |█████████████████████| 6/6 [18.4ms elapsed, 0s remaining, 326.5 samples/s]    \n",
      "Loading class: Toothbrush\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 12 (<459) samples matching your requirements\n",
      "Found 1 images, downloading the remaining 11\n",
      " 100% |█████████████████████| 11/11 [3.1s elapsed, 0s remaining, 3.6 files/s]    \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |███████████████████| 12/12 [31.1ms elapsed, 0s remaining, 386.4 samples/s]     \n",
      "Dataset 'open-images-v7-toothbrush-test' created\n",
      " 100% |███████████████████| 12/12 [28.2ms elapsed, 0s remaining, 424.9 samples/s]    \n",
      "Loading class: Refrigerator\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 110 (<459) samples matching your requirements\n",
      "Found 17 images, downloading the remaining 93\n",
      " 100% |█████████████████████| 93/93 [5.8s elapsed, 0s remaining, 35.4 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 110/110 [509.4ms elapsed, 0s remaining, 215.9 samples/s]      \n",
      "Dataset 'open-images-v7-refrigerator-test' created\n",
      " 100% |█████████████████| 110/110 [690.2ms elapsed, 0s remaining, 159.4 samples/s]      \n",
      "Loading class: Couch\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 125 (<459) samples matching your requirements\n",
      "Found 1 images, downloading the remaining 124\n",
      " 100% |███████████████████| 124/124 [6.8s elapsed, 0s remaining, 29.5 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 125/125 [667.9ms elapsed, 0s remaining, 187.6 samples/s]      \n",
      "Dataset 'open-images-v7-couch-test' created\n",
      " 100% |█████████████████| 125/125 [972.3ms elapsed, 0s remaining, 128.6 samples/s]      \n",
      "Loading class: Chair\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Found 36 images, downloading the remaining 423\n",
      " 100% |███████████████████| 423/423 [13.7s elapsed, 0s remaining, 36.0 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 459/459 [3.3s elapsed, 0s remaining, 139.1 samples/s]      \n",
      "Dataset 'open-images-v7-chair-test' created\n",
      " 100% |█████████████████| 459/459 [4.5s elapsed, 0s remaining, 105.9 samples/s]      \n",
      "Loading class: Umbrella\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 106 (<459) samples matching your requirements\n",
      "Found 4 images, downloading the remaining 102\n",
      " 100% |███████████████████| 102/102 [10.5s elapsed, 0s remaining, 3.7 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 106/106 [1.0s elapsed, 0s remaining, 105.8 samples/s]         \n",
      "Dataset 'open-images-v7-umbrella-test' created\n",
      " 100% |█████████████████| 106/106 [1.3s elapsed, 0s remaining, 81.9 samples/s]          \n",
      "Loading class: Knife\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 167 (<459) samples matching your requirements\n",
      "Found 3 images, downloading the remaining 164\n",
      " 100% |███████████████████| 164/164 [8.9s elapsed, 0s remaining, 15.4 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 167/167 [370.7ms elapsed, 0s remaining, 450.5 samples/s]      \n",
      "Dataset 'open-images-v7-knife-test' created\n",
      " 100% |█████████████████| 167/167 [495.3ms elapsed, 0s remaining, 337.2 samples/s]      \n",
      "Loading class: Suitcase\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 55 (<459) samples matching your requirements\n",
      "Found 12 images, downloading the remaining 43\n",
      " 100% |█████████████████████| 43/43 [5.4s elapsed, 0s remaining, 17.3 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |███████████████████| 55/55 [197.4ms elapsed, 0s remaining, 278.6 samples/s]     \n",
      "Dataset 'open-images-v7-suitcase-test' created\n",
      " 100% |███████████████████| 55/55 [252.1ms elapsed, 0s remaining, 219.8 samples/s]      \n",
      "Loading class: Sunglasses\n",
      "Downloading split 'test' to 'D://Data\\open-images-v7\\test' if necessary\n",
      "Only found 439 (<459) samples matching your requirements\n",
      "Found 7 images, downloading the remaining 432\n",
      " 100% |███████████████████| 432/432 [17.9s elapsed, 0s remaining, 28.5 files/s]      \n",
      "Dataset info written to 'D://Data\\open-images-v7\\info.json'\n",
      "Loading 'open-images-v7' split 'test'\n",
      " 100% |█████████████████| 439/439 [5.6s elapsed, 0s remaining, 86.8 samples/s]      \n",
      "Dataset 'open-images-v7-sunglasses-test' created\n",
      " 100% |█████████████████| 439/439 [7.4s elapsed, 0s remaining, 61.1 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "import os\n",
    "\n",
    "\n",
    "classes = [\n",
    "    \"Bowl\", \"Backpack\", \"Laptop\", \"Oven\", \"Toaster\", \"Mouse\", \"Bottle\",\n",
    "    \"Tennis racket\", \"Clock\", \"Tie\", \"Wine glass\", \"Spoon\", \"Scissors\",\n",
    "    \"Toothbrush\", \"Refrigerator\", \"Couch\", \"Chair\", \"Umbrella\", \"Knife\",\n",
    "    \"Suitcase\", \"Sunglasses\"\n",
    "]\n",
    "\n",
    "# Specify your custom download directory\n",
    "dataset_dir = \"D://Data\"  # Replace with your desired path\n",
    "\n",
    "# Set the base data directory for FiftyOne\n",
    "fo.config.dataset_zoo_dir = dataset_dir\n",
    "\n",
    "# Create an empty dataset\n",
    "accumulated_dataset = fo.Dataset()\n",
    "\n",
    "for cls in classes:\n",
    "    print(f\"Loading class: {cls}\")\n",
    "\n",
    "    # Generate a unique dataset name for each class\n",
    "    dataset_name = f\"open-images-v7-{cls.lower().replace(' ', '-')}-test\"\n",
    "\n",
    "    dataset = foz.load_zoo_dataset(\n",
    "        \"open-images-v7\",\n",
    "        split=\"test\",\n",
    "        classes=[cls],\n",
    "        label_types=[\"detections\"],\n",
    "        max_samples=459,\n",
    "        seed=51,\n",
    "        shuffle=True,\n",
    "        dataset_name=dataset_name  # Use the unique dataset name here\n",
    "    )\n",
    "\n",
    "    # Add samples to the accumulated dataset\n",
    "    accumulated_dataset.add_samples(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:39:51.857860200Z",
     "start_time": "2023-11-22T16:34:54.480255500Z"
    }
   },
   "id": "faea993f8cf31684"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "accumulated_dataset.default_classes = classes\n",
    "view = accumulated_dataset.filter_labels(\"ground_truth\", \n",
    "                             fo.ViewField(\"label\").is_in(classes))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:40:03.364009600Z",
     "start_time": "2023-11-22T16:40:03.357894400Z"
    }
   },
   "id": "bb236d7eaea993f3"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'D://Data//open-images-v7' already exists; export will be merged with existing files\n",
      " 100% |███████████████| 3538/3538 [26.2s elapsed, 0s remaining, 59.6 samples/s]       \n"
     ]
    }
   ],
   "source": [
    "# Export the dataset in YOLOv5 format\n",
    "view.export(\n",
    "    export_dir=\"D://Data//open-images-v7\",  # Replace with your desired path\n",
    "    dataset_type=fo.types.YOLOv5Dataset,\n",
    "    split=\"test\",  # You can specify the split (train, val, test) if needed\n",
    "    classes=classes\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:40:39.445153800Z",
     "start_time": "2023-11-22T16:40:13.144362500Z"
    }
   },
   "id": "f9710de5d7318154"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2-3. OpenImagesV7 + Custom Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8ce878392b9a6c"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 42679/42679 [2.7m elapsed, 0s remaining, 253.9 samples/s]      \n",
      " 100% |███████████████| 3380/3380 [11.0s elapsed, 0s remaining, 309.5 samples/s]      \n",
      " 100% |███████████████| 1279/1279 [4.2s elapsed, 0s remaining, 303.8 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "\n",
    "# Initialize the main dataset\n",
    "name = \"OpenImages+Custom-1sttry\"\n",
    "dataset = fo.Dataset(name)\n",
    "\n",
    "# Load and tag the first dataset\n",
    "dataset_dir = \"D:\\Data\\open-images-v7\"\n",
    "splits = [\"train\", \"test\", \"val\"]\n",
    "for split in splits:\n",
    "    dataset.add_dir(\n",
    "        dataset_dir=dataset_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=[split]\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:51:12.996065600Z",
     "start_time": "2023-11-22T16:46:12.238285400Z"
    }
   },
   "id": "5106c0994dcf0100"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████| 3023/3023 [11.3s elapsed, 0s remaining, 279.2 samples/s]      \n",
      " 100% |█████████████████| 459/459 [1.7s elapsed, 0s remaining, 265.9 samples/s]         \n",
      " 100% |█████████████████| 922/922 [3.4s elapsed, 0s remaining, 283.8 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Load and tag the second dataset into a separate Dataset object\n",
    "dataset_dir2 = \"D://Data//sweatshirts_final\"\n",
    "for split in splits:\n",
    "    dataset.merge_dir(\n",
    "        dataset_dir = dataset_dir2,\n",
    "        dataset_type = fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        tags=[split],\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T16:53:34.762515400Z",
     "start_time": "2023-11-22T16:53:15.582795700Z"
    }
   },
   "id": "cd2e84b41265a3a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'D://Data//merged_final_new' already exists; export will be merged with existing files\n",
      " 100% |█████████████| 45702/45702 [38.0m elapsed, 0s remaining, 46.0 samples/s]      \n",
      "Directory 'D://Data//merged_final_new' already exists; export will be merged with existing files\n",
      " 100% |███████████████| 3839/3839 [2.5m elapsed, 0s remaining, 63.6 samples/s]      \n",
      "Directory 'D://Data//merged_final_new' already exists; export will be merged with existing files\n",
      " 100% |███████████████| 2201/2201 [1.1m elapsed, 0s remaining, 72.9 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "new_classes = [\n",
    "    \"Bowl\", \"Backpack\", \"Laptop\", \"Oven\", \"Toaster\", \"Mouse\", \"Bottle\",\n",
    "    \"Tennis racket\", \"Clock\", \"Tie\", \"Wine glass\", \"Spoon\", \"Scissors\",\n",
    "    \"Toothbrush\", \"Refrigerator\", \"Couch\", \"Chair\", \"Umbrella\", \"Knife\",\n",
    "    \"Suitcase\", \"Sunglasses\",\"sweatshirts\"\n",
    "]\n",
    "\n",
    "# Export each split\n",
    "export_dir = \"D://Data//merged_final_new\"\n",
    "for split in splits:\n",
    "    split_view = dataset.match(fo.ViewField(\"tags\").contains(split))\n",
    "    split_view.export(\n",
    "        export_dir=export_dir,\n",
    "        dataset_type=fo.types.YOLOv5Dataset,\n",
    "        split=split,\n",
    "        classes=new_classes\n",
    "    )\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-22T18:51:34.012919300Z",
     "start_time": "2023-11-22T18:09:57.457155Z"
    }
   },
   "id": "80c97cb669626054"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "print(\"end\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T02:20:51.055648700Z",
     "start_time": "2023-11-23T02:20:51.050131Z"
    }
   },
   "id": "a9c2459c2a936661"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "19ed20d2891e5024"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
