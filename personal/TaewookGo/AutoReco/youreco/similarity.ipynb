{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb63aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "class SimBck: # Similairty Backbone = Resnet50\n",
    "    def __init__(self,\n",
    "                    dir = False,\n",
    "                    model = torchvision.models.resnet50(pretrained = True),\n",
    "                    model_weights = torchvision.models.ResNet50_Weights.DEFAULT):\n",
    "        '''\n",
    "        dir : file directory of fine-tuned model state_dict. Default is pre-trained model\n",
    "        model : pretrained model, resnet50(ImageNet_V2)\n",
    "        model_weights : weights of pretrained model\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.weights = model_weights\n",
    "        self.transform = self.assign_transform()\n",
    "        self.device = self.set_device()\n",
    "\n",
    "        if dir:\n",
    "            self.model.load_state_dict(torch.load(dir))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    def assign_transform(self):\n",
    "        try:\n",
    "            preprocess = self.weights.transforms()\n",
    "\n",
    "        except Exception:\n",
    "            preprocess = transforms.Compose(\n",
    "              [\n",
    "                  transforms.ToTensor(),\n",
    "                  transforms.Normalize(\n",
    "                      mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                  ),\n",
    "              ]\n",
    "            )\n",
    "\n",
    "        return preprocess\n",
    "\n",
    "    def set_device(self):\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "        return device\n",
    "\n",
    "    def initiate_model(self): # model initiate 후 eval 모드로 바꿈\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        return self.model.eval()\n",
    "\n",
    "class YouRecoSIm(SimBck):\n",
    "    def __init__(self, dir = False):\n",
    "        super(YouRecoSIm, self).__init__(dir)\n",
    "        self.initiate_model()\n",
    "        self.index_DB = faiss.read_index('Youreco_vectorDB.index') # DB 저장소\n",
    "\n",
    "    def feature_extractor(self,image_dir, query_img, box): # Resnet-50으로부터 feature extraction/extra classification\n",
    "        query_img = Image.open(f'{image_dir}/{query_img}.jpg').convert('RGB')\n",
    "        img_trans = self.transform(query_img)\n",
    "        img_trans = img_trans.unsqueeze(0) # (1, 3, 224, 224)\n",
    "        img_trans = img_trans.to(self.set_device())\n",
    "\n",
    "        # Embedding vector = (1, 2048)\n",
    "        embed_feature = []\n",
    "        hook = self.model.avgpool.register_forward_hook(\n",
    "          lambda self, input, output: embed_feature.append(output.flatten().unsqueeze(0)))\n",
    "        res = self.model(img_trans, box)\n",
    "        hook.remove()\n",
    "\n",
    "        # Classification\n",
    "        res = self.model(img_trans, box)\n",
    "        _, cls = torch.max(res.data, 1)\n",
    "\n",
    "        return embed_feature[0], cls\n",
    "\n",
    "    def retrieval_similar(self, image_dir, query_img, box):\n",
    "        query_img_embedding, category = self.feature_extractor(image_dir, query_img, box)\n",
    "        \n",
    "        n = 4\n",
    "        while True:\n",
    "            # query image may not be in similarity vector space.\n",
    "            distance, indices = self.index_DB.search(query_img_embedding.reshape(1, -1), n)\n",
    "            \n",
    "            if len(set(indices.squeeze(0))) == 4:\n",
    "                # 유사도 랭크 순으로 중복 제거한 itemid list\n",
    "                indices = sorted(set(indices.squeeze(0)), key = lambda x : list(indices.squeeze(0)).index(x) )\n",
    "                \n",
    "                return indices, category  \n",
    "                \n",
    "            else:\n",
    "                n += 1\n",
    "                \n",
    "        return\n",
    "\n",
    "def similarity_result(model, key_result, image_dir):\n",
    "    similar_itemid_list = list() # 유사 이미지 상품 itemid\n",
    "    category_list = list() # 각 object의 classification 결과의 category\n",
    "    for obj in key_result:\n",
    "        indices, category = model.retrieval_similar(image_dir, obj[0], obj[3])\n",
    "        similar_itemid_list.append(indices)\n",
    "        category_list.append(category)\n",
    "    \n",
    "    return similar_itemid_list, category_list "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
